{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "from pyopia.classify import Classify\n",
    "import exampledata\n",
    "import pyopia.io\n",
    "from pyopia.pipeline import Pipeline, Common\n",
    "from pyopia.instrument.silcam import SilCamLoad, ImagePrep\n",
    "from pyopia.process import CalculateStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_data\\\\D20181101T142731.838206.silc',\n",
       " 'raw_data\\\\D20181101T142732.772669.silc',\n",
       " 'raw_data\\\\D20181101T142733.765097.silc',\n",
       " 'raw_data\\\\D20181101T142734.292793.silc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = exampledata.get_example_silc_image()\n",
    "\n",
    "files = glob('raw_data/*.silc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example future pre-processing admin:\n",
    "# 1) config file config load\n",
    "# 2) build steps dict from loaded file\n",
    "# 3) establish non-processing related metadata\n",
    "\n",
    "datafile_hdf = 'proc/test'\n",
    "model_path = exampledata.get_example_model()\n",
    "threshold = 0.85\n",
    "\n",
    "steps = {'common': Common(),\n",
    "         'load': SilCamLoad(),\n",
    "         'classifier': Classify(model_path=model_path),\n",
    "         'imageprep': ImagePrep(),\n",
    "         'statextract': CalculateStats(threshold=threshold),\n",
    "         'output': pyopia.io.StatsH5(datafile_hdf)}\n",
    "\n",
    "processing_pipeline = Pipeline(steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Background correction not implemented!\n",
      "segment\n",
      "clean\n",
      "21.7% saturation\n",
      "measure\n",
      "  870 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 870 IMAGES from 870\n",
      "WARNING: Background correction not implemented!\n",
      "segment\n",
      "clean\n",
      "19.7% saturation\n",
      "measure\n",
      "  874 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 874 IMAGES from 874\n",
      "WARNING: Background correction not implemented!\n",
      "segment\n",
      "clean\n",
      "19.7% saturation\n",
      "measure\n",
      "  918 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 918 IMAGES from 918\n",
      "WARNING: Background correction not implemented!\n",
      "segment\n",
      "clean\n",
      "19.3% saturation\n",
      "measure\n",
      "  930 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 930 IMAGES from 930\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    stats = processing_pipeline.run(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified:\n",
      "    2022-11-09 22:04:09.029022\n",
      "Pipeline steps:\n",
      "    \n",
      "1) Step: common\n",
      "   Type: <class 'pyopia.pipeline.Common'>\n",
      "   Vars: {}\n",
      "2) Step: load\n",
      "   Type: <class 'pyopia.instrument.silcam.SilCamLoad'>\n",
      "   Vars: {}\n",
      "3) Step: classifier\n",
      "   Type: <class 'pyopia.classify.Classify'>\n",
      "   Vars: {'model_path': 'keras_model.h5', 'class_labels': Index(['oil', 'other', 'bubble', 'faecal_pellets', 'copepod', 'diatom_chain',\n",
      "       'oily_gas'],\n",
      "      dtype='object'), 'model': <keras.engine.sequential.Sequential object at 0x000001C9C821FFA0>}\n",
      "4) Step: imageprep\n",
      "   Type: <class 'pyopia.instrument.silcam.ImagePrep'>\n",
      "   Vars: {}\n",
      "5) Step: statextract\n",
      "   Type: <class 'pyopia.process.CalculateStats'>\n",
      "   Vars: {'minimum_area': 12, 'threshold': 0.85, 'real_time_stats': False, 'max_coverage': 30, 'max_particles': 5000}\n",
      "6) Step: output\n",
      "   Type: <class 'pyopia.io.StatsH5'>\n",
      "   Vars: {'datafilename': 'proc/test'}\n",
      "\n",
      "PyOpia version:\n",
      "    0.0.13\n"
     ]
    }
   ],
   "source": [
    "# display metadata in the h5\n",
    "pyopia.io.show_h5_meta(datafile_hdf + '-STATS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats header:  Index(['major_axis_length', 'minor_axis_length', 'equivalent_diameter',\n",
      "       'solidity', 'minr', 'minc', 'maxr', 'maxc', 'probability_oil',\n",
      "       'probability_other', 'probability_bubble', 'probability_faecal_pellets',\n",
      "       'probability_copepod', 'probability_diatom_chain',\n",
      "       'probability_oily_gas', 'export name', 'timestamp', 'saturation'],\n",
      "      dtype='object')\n",
      "Total number of particles:  9682\n",
      "Number of raw images:  4\n"
     ]
    }
   ],
   "source": [
    "import pyopia.statistics\n",
    "# load the stats DataFrame from the h5 file\n",
    "stats = pd.read_hdf(datafile_hdf + '-STATS.h5', 'ParticleStats/stats')\n",
    "print('stats header: ', stats.columns)\n",
    "print('Total number of particles: ', len(stats))\n",
    "print('Number of raw images: ', pyopia.statistics.count_images_in_stats(stats))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35ab0c005d63a5587fede8db5b2b16b081d9aece903d58f7211748c218ea86a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
