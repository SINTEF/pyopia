{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopia.background\n",
    "import pyopia.classify\n",
    "import pyopia.instrument.silcam\n",
    "import pyopia.instrument.holo\n",
    "import pyopia.io\n",
    "import pyopia.pipeline\n",
    "import pyopia.plotting\n",
    "import pyopia.process\n",
    "import pyopia.statistics\n",
    "import exampledata\n",
    "\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a TOML config file containing all setttings, and pipeline steps\n",
    "\n",
    "This creates a dict of all settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_settings = pyopia.io.load_toml('config.toml')\n",
    "toml_settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the steps dict\n",
    "\n",
    "This is the dict that is given to `pyopia.pipeline.Pipeline`\n",
    "\n",
    "The dict created here is not human-readable (but that shouldn't matter, since this came from the human-readable TOML config)\n",
    "\n",
    "We are not including the disc writing in the pipeline for this example - so we can better demonstrate the formatted output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps = pyopia.pipeline.build_steps(toml_settings['steps'])\n",
    "#steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline = pyopia.pipeline.Pipeline(toml_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "\n",
    "(same as normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the pipeline and run the initial steps\n",
    "processing_pipeline = pyopia.pipeline.Pipeline(toml_settings)\n",
    "\n",
    "# Load an image (from the test suite)\n",
    "filename = exampledata.get_example_silc_image()\n",
    "\n",
    "# Process the image to obtain the stats dataframe\n",
    "stats = processing_pipeline.run(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to disc\n",
    "\n",
    "We will convert the STATS DataFrame into xarray for efficiency and easier metadata handling and easy writing to NetCDF.\n",
    "\n",
    "This will use the steps part of the TOML configuration as metadata (attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyopia.io.write_stats(\n",
    "        'proc/test',\n",
    "        stats,\n",
    "        steps_string=toml_settings['steps'],\n",
    "        append=False,\n",
    "        format='nc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data again\n",
    "\n",
    "Then later, we can load the data again from NetCDF using xarray\n",
    "\n",
    "xarray DataSets are presented nicely in notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstats = xarray.open_dataset('proc/test-STATS.nc')\n",
    "xstats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alter settings and re-process\n",
    "\n",
    "What if we wanted to re-process this dataset with a different segmentation threshold?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the TOML steps from the xarray DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_steps = pyopia.pipeline.steps_from_xstats(xstats)\n",
    "toml_steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter the setting we want to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_steps['segmentation']['threshold'] = 0.9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-build the pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = pyopia.pipeline.build_steps(toml_steps)\n",
    "steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-process the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the pipeline and run the initial steps\n",
    "processing_pipeline = pyopia.pipeline.Pipeline(steps)\n",
    "\n",
    "# Load an image (from the test suite)\n",
    "filename = exampledata.get_example_silc_image()\n",
    "\n",
    "# Process the image to obtain the stats dataframe\n",
    "stats = processing_pipeline.run(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis\n",
    "\n",
    "At this point we could write this to disc again (like before)\n",
    "\n",
    "and/or we could build a new, correctly formatted, xarray for immediate use (which we will do here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstats_modified = pyopia.io.make_xstats(stats, toml_steps)\n",
    "xstats_modified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "We can plot directly from xarray in exactly the same way as from the Pandas DataFrame (so it doesn't matter which you use here). The benefit of 'xstats' as an xarray is that it now contains it's own metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dias, vd = pyopia.statistics.vd_from_stats(xstats, 24)\n",
    "\n",
    "plt.plot(dias, vd, label=f\"Threshold={pyopia.pipeline.steps_from_xstats(xstats)['segmentation']['threshold']}\")\n",
    "plt.xscale('log')\n",
    "plt.xlabel('ECD [um]')\n",
    "plt.ylabel('Volume Distribution [uL/sample vol.]')\n",
    "\n",
    "dias_modified, vd_modified = pyopia.statistics.vd_from_stats(xstats_modified, 24)\n",
    "\n",
    "plt.plot(dias_modified, vd_modified, '--', label=f\"Threshold={pyopia.pipeline.steps_from_xstats(xstats_modified)['segmentation']['threshold']}\")\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
