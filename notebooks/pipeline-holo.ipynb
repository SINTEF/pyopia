{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example hologram processing pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 00 - configure warnings and autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 01 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pyopia.classify import Classify\n",
    "import pyopia.process\n",
    "import pyopia.io\n",
    "import pyopia.background\n",
    "import pyopia.statistics\n",
    "import exampledata\n",
    "from pyopia.pipeline import Pipeline\n",
    "import pyopia.instrument.holo as holo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#download the default holo test data and create file list\n",
    "foldername = exampledata.get_folder_from_holo_repository(\"holo_test_data_01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the holo test data\n",
    "# either holo_test_data_01 (default) or holo_test_data_02\n",
    "infolder = exampledata.get_folder_from_holo_repository(\"holo_test_data_02\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 03 - Define runtime settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder of input data\n",
    "infolder = 'holo_test_data_01'\n",
    "\n",
    "# path to folder of output data (will be created)\n",
    "outfolder = 'proc1'\n",
    "\n",
    "# name of output statistics file (if already exists will be removed)\n",
    "outfilename = 'holotest'\n",
    "\n",
    "# path to classifier model to use (here we download and use an example model)\n",
    "model_path = exampledata.get_example_model()\n",
    "\n",
    "# segmentation threshold \n",
    "threshold = 0.9\n",
    "\n",
    "# number of images to use as background (recommend >=10) - for either static or moving background removal\n",
    "average_window = 10  \n",
    "\n",
    "# hologram reconstruction settings\n",
    "holo_initial_settings = {'pixel_size': 4.4, # pixel size in um\n",
    "                        'wavelength': 658, # laser wavelength in nm\n",
    "                        'n': 1.33, # index of refraction of sample volume medium (1.33 for water)\n",
    "                        'offset': 26, # offset to start of sample volume in mm\n",
    "                        'minZ': 0, # minimum reconstruction distance within sample volume in mm\n",
    "                        'maxZ': 50, # maximum reconstruction distance within sample volume in mm\n",
    "                        'stepZ': 0.5} #step size in mm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 04 - Setup folders & input file lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output folder\n",
    "os.makedirs(outfolder, exist_ok=True)\n",
    "\n",
    "# remove pre-existing output file (as statistics for each image are appended to it)\n",
    "datafile_hdf = os.path.join(outfolder,'holotest')\n",
    "if os.path.exists(datafile_hdf + '-STATS.h5'):\n",
    "  os.remove(datafile_hdf + '-STATS.h5')\n",
    "\n",
    "# get sorted list of input files\n",
    "files = sorted(glob(os.path.join(infolder, '*.pgm')))\n",
    "\n",
    "# create list of files for initial creation of background file\n",
    "bgfiles = files[:average_window]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 05 - Setup pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the steps to use in the processing pipeline - given as a label and the Class with options\n",
    "steps = {\n",
    "         'initial': holo.Initial(files[0], **holo_initial_settings), # initial step, run once on pipeline initialisation - arguments a filename to use for sizing the image and hologram reconstruction settings from Step 03\n",
    "         'classifier': Classify(model_path=model_path), # sets up classifier model, run once on pipeline initialisation - argument is the path to the classification model to use from Step 03\n",
    "         'create background': pyopia.background.CreateBackground(bgfiles, pyopia.instrument.holo.load_image),\n",
    "         'load': holo.Load(),\n",
    "         'correct background': pyopia.background.CorrectBackgroundAccurate(pyopia.background.shift_bgstack_accurate),\n",
    "         'reconstruct': holo.Reconstruct(stack_clean=0.02),\n",
    "         'focus': holo.Focus(pyopia.instrument.holo.std_map,threshold=threshold,focus_function=pyopia.instrument.holo.find_focus_sobel),\n",
    "         'segmentation': pyopia.process.Segment(threshold=threshold),\n",
    "         'statextract': pyopia.process.CalculateStats(export_outputpath=outfolder),\n",
    "         'merge holo stats': holo.MergeStats(),\n",
    "         'output': pyopia.io.StatsH5(datafile_hdf)\n",
    "         }\n",
    "\n",
    "# now initialise the pipeline\n",
    "processing_pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a test run with just the first few input files\n",
    "for filename in files[:5]:\n",
    "    stats = processing_pipeline.run(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metadata in the h5\n",
    "pyopia.io.show_h5_meta(datafile_hdf + '-STATS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the stats DataFrame from the h5 file\n",
    "stats = pd.read_hdf(datafile_hdf + '-STATS.h5', 'ParticleStats/stats')\n",
    "print('stats header: ', stats.columns)\n",
    "print('Total number of particles: ', len(stats))\n",
    "# Calculate the volume distribution from the stats DataFrame.\n",
    "dias, vd = pyopia.statistics.vd_from_stats(stats, 24)\n",
    "\n",
    "# plot the volume distribution\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(dias, vd)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('ECD [um]')\n",
    "plt.ylabel('Volume Distribution [uL/sample vol.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram of focus locations\n",
    "import numpy as np\n",
    "plt.style.use('dark_background')\n",
    "zval = np.arange(holo_initial_settings['minZ'], holo_initial_settings['maxZ'], holo_initial_settings['stepZ'])\n",
    "plt.hist(zval[stats.ifocus-1],len(zval))\n",
    "plt.xlim(zval[0],zval[-1])\n",
    "plt.xlabel('Z [mm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_mont = pyopia.statistics.make_montage(datafile_hdf + '-STATS.h5',holo_initial_settings[\"pixel_size\"],outfolder,\n",
    "    auto_scaler=1000, msize=2048, maxlength=100000, crop_stats=None)\n",
    "pyopia.statistics.montage_plot(im_mont,holo_initial_settings['pixel_size'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce1ed1d0a0c70742da6311dac6d4156324f6bcf6d9d02a2d90ecedc750502898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
