{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example hologram processing pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 00 - configure warnings and autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 01 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pyopia.classify import Classify\n",
    "import pyopia.process\n",
    "import pyopia.io\n",
    "import pyopia.background\n",
    "import pyopia.statistics\n",
    "import pyopia.plotting\n",
    "import skimage.io\n",
    "import exampledata\n",
    "from pyopia.pipeline import Pipeline\n",
    "import pyopia.instrument.holo as holo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyopia' from '/home/raymondne/code/pyopia-dev/pyopia/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyopia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 02 - (run once) Download test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holo_test_data_01 already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# download the holo test data\n",
    "# either holo_test_data_01 (default) or holo_test_data_02\n",
    "infolder = exampledata.get_folder_from_holo_repository(\"holo_test_data_01\", existsok=True)\n",
    "infolder = os.path.join(infolder, \"*.pgm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 03 - Define input and output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras_model.h5 already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# path to folder of input data\n",
    "infolder = 'holo_test_data_01/*.pgm'\n",
    "\n",
    "# path to folder of output data (will be created)\n",
    "outfolder = 'proc1'\n",
    "\n",
    "# name of output statistics file (if already exists will be removed)\n",
    "outfilename = 'holotest'\n",
    "\n",
    "# path to classifier model to use (here we download and use an example model)\n",
    "model_path = exampledata.get_example_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 04 - Setup folders configured in Step 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output folder\n",
    "os.makedirs(outfolder, exist_ok=True)\n",
    "\n",
    "# remove pre-existing output file (as statistics for each image are appended to it)\n",
    "datafile_nc = os.path.join(outfolder, outfilename)\n",
    "if os.path.isfile(datafile_nc + '-STATS.nc'):\n",
    "  os.remove(datafile_nc + '-STATS.nc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 05 - Setup pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising pipeline\n",
      "raw_files: holo_test_data_01/*.pgm\n",
      "Initial  ready with: {'wavelength': 658, 'n': 1.33, 'offset': 27, 'minZ': 0, 'maxZ': 50, 'stepZ': 0.5}  and data dict_keys(['cl', 'settings', 'raw_files'])\n",
      "Using first raw file from list in general settings to determine image dimensions\n",
      "Build kernel with pixel_size =  4.4 um\n",
      "HoloInitial done 2024-08-09 15:07:46.982613\n",
      "WARNING: Classification assumes loaded images have values in the range 0-255\n",
      "Classify  ready with: {'model_path': 'keras_model.h5'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack'])\n",
      "Pipeline ready with these data:  ['cl', 'settings', 'raw_files', 'kern', 'im_stack']\n"
     ]
    }
   ],
   "source": [
    "# define the configuration to use in the processing pipeline - given as a dictionary - with some values defined above\n",
    "pipeline_config = {\n",
    "   'general': {\n",
    "      'raw_files': infolder,\n",
    "      'pixel_size': 4.4 # pixel size in um \n",
    "   },\n",
    " 'steps': {\n",
    "      ### start of steps run once on pipeline initialisation\n",
    "      # initial step to setup hologram reconstruction kernel - arguments are hologram reconstruction settings\n",
    "      'initial': {\n",
    "         'pipeline_class': 'pyopia.instrument.holo.Initial',\n",
    "         'wavelength': 658, # laser wavelength in nm\n",
    "         'n': 1.33, # index of refraction of sample volume medium (1.33 for water)\n",
    "         'offset': 27, # offset to start of sample volume in mm\n",
    "         'minZ': 0, # minimum reconstruction distance within sample volume in mm\n",
    "         'maxZ': 50, # maximum reconstruction distance within sample volume in mm\n",
    "         'stepZ': 0.5 #step size in mm\n",
    "      },\n",
    "      # sets up classifier model, runs once on pipeline initialisation - argument is the path to the classification model to use from Step 03\n",
    "      'classifier': {\n",
    "         'pipeline_class': 'pyopia.classify.Classify',\n",
    "         'model_path': model_path\n",
    "      },\n",
    "      ### start of steps applied to every image\n",
    "      # load the image using instrument-specific loading function \n",
    "      'load': {\n",
    "         'pipeline_class': 'pyopia.instrument.holo.Load'\n",
    "      },\n",
    "      # apply background correction - argument is which method to use:\n",
    "      # 'accurate' - recommended method for moving background\n",
    "      # 'fast' - faster method for realtime applications\n",
    "      # 'pass' - omit background correction\n",
    "      'correctbackground': {\n",
    "         'pipeline_class': 'pyopia.background.CorrectBackgroundAccurate',\n",
    "         'average_window': 10,\n",
    "         'bgshift_function': 'accurate'\n",
    "      },\n",
    "      # hologram reconstruction step - arguments are:\n",
    "      # stack_clean - is how much stack cleaning (% dimmest pixels to remove) to apply - set to 0 to omit cleaning\n",
    "      # forward_filter_option - switch to control filtering in frequency domain (0=none,1=DC only,2=zero ferquency/default)\n",
    "      # inverse_output_option - switch to control optional scaling of output intensity (0=square/default,1=linear)\n",
    "      'reconstruct': {\n",
    "         'pipeline_class': 'pyopia.instrument.holo.Reconstruct',\n",
    "         'stack_clean': 0.02,\n",
    "         'forward_filter_option': 2,\n",
    "         'inverse_output_option': 0\n",
    "      },\n",
    "      # focussing step - arguments are:\n",
    "      # which summarisation method to use:\n",
    "      # 'std_map' (default) - takes standard deviation of values through stack\n",
    "      # 'max_map' - takes maximum intensity value through stack\n",
    "      # threshold is global segmentation threshold to apply to stack summary\n",
    "      # which focus function to use:\n",
    "      # 'find_focis_imax' (default) - finds focus using plane of maximum intensity\n",
    "      # 'find_focus_sobel' - finds focus using edge sharpness\n",
    "      # focus options are:\n",
    "      # increase_depth_of_field (bool, default False) - finds max of planes adjacent to optimum focus plane\n",
    "      # merge_adjacent_particles (int, default 0) - merges adjacent particles within stack summary using this pixel radius\n",
    "      'focus': {\n",
    "         'pipeline_class': 'pyopia.instrument.holo.Focus',\n",
    "         'stacksummary_function': 'max_map',\n",
    "         'threshold': 0.9,\n",
    "         'increase_depth_of_field': True,\n",
    "         'focus_function': 'find_focus_sobel',\n",
    "         'merge_adjacent_particles': 2\n",
    "      },\n",
    "      # segmentation of focussed particles - argument is threshold to apply (can be different to Focus step)\n",
    "      'segmentation': {\n",
    "         'pipeline_class': 'pyopia.process.Segment',\n",
    "         'threshold': 0.9\n",
    "      },\n",
    "      # extraction of particle statistics - arguments are:\n",
    "      # export_outputpath - is output folder for image-specific outputs for montage creation (can be omitted)\n",
    "      # propnames - is list of skimage regionprops to export to stats (optional - must contain default values that can be appended to)\n",
    "      'statextract': {\n",
    "         'pipeline_class': 'pyopia.process.CalculateStats',\n",
    "         'export_outputpath': outfolder, \n",
    "         'propnames': ['major_axis_length', 'minor_axis_length', 'equivalent_diameter', \n",
    "                              'feret_diameter_max', 'equivalent_diameter_area']\n",
    "      },\n",
    "      # step to merge hologram-specific information (currently focus depth & original filename) into output statistics file\n",
    "      'mergeholostats': {\n",
    "         'pipeline_class': 'pyopia.instrument.holo.MergeStats',\n",
    "      },\n",
    "      # write the output NetCDF statistics file\n",
    "      'output': {\n",
    "         'pipeline_class': 'pyopia.io.StatsToDisc',\n",
    "         'output_datafile': datafile_nc\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "# now initialise the pipeline\n",
    "processing_pipeline = Pipeline(pipeline_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 06 - Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename'])\n",
      "holo_test_data_01/001-2043.pgm\n",
      "D20180706T181539.002043\n",
      "2018-07-06 18:15:39.002043\n",
      "CorrectBackgroundAccurate  ready with: {'average_window': 10, 'bgshift_function': 'accurate'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw'])\n",
      "Reconstruct  ready with: {'stack_clean': 0.02, 'forward_filter_option': 2, 'inverse_output_option': 0}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc'])\n",
      "Focus  ready with: {'stacksummary_function': 'max_map', 'threshold': 0.9, 'increase_depth_of_field': True, 'focus_function': 'find_focus_sobel', 'merge_adjacent_particles': 2}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc'])\n",
      "segment\n",
      "clean\n",
      "  713 particles found\n",
      "Segment  ready with: {'threshold': 0.9}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus'])\n",
      "segment\n",
      "clean\n",
      "CalculateStats  ready with: {'export_outputpath': 'proc1', 'propnames': ['major_axis_length', 'minor_axis_length', 'equivalent_diameter', 'feret_diameter_max', 'equivalent_diameter_area']}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw'])\n",
      "statextract\n",
      "0.0% saturation\n",
      "measure\n",
      "  0 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 0 IMAGES from 0\n",
      "MergeStats  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "StatsToDisc  ready with: {'output_datafile': 'proc1/holotest'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Load  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "holo_test_data_01/001-2044.pgm\n",
      "D20180706T181545.002044\n",
      "2018-07-06 18:15:45.002044\n",
      "CorrectBackgroundAccurate  ready with: {'average_window': 10, 'bgshift_function': 'accurate'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Reconstruct  ready with: {'stack_clean': 0.02, 'forward_filter_option': 2, 'inverse_output_option': 0}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Focus  ready with: {'stacksummary_function': 'max_map', 'threshold': 0.9, 'increase_depth_of_field': True, 'focus_function': 'find_focus_sobel', 'merge_adjacent_particles': 2}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "segment\n",
      "clean\n",
      "  65 particles found\n",
      "Segment  ready with: {'threshold': 0.9}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "segment\n",
      "clean\n",
      "CalculateStats  ready with: {'export_outputpath': 'proc1', 'propnames': ['major_axis_length', 'minor_axis_length', 'equivalent_diameter', 'feret_diameter_max', 'equivalent_diameter_area']}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "statextract\n",
      "1.2% saturation\n",
      "measure\n",
      "  65 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 65 IMAGES from 65\n",
      "MergeStats  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "StatsToDisc  ready with: {'output_datafile': 'proc1/holotest'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Load  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "holo_test_data_01/001-2055.pgm\n",
      "D20180706T181643.002055\n",
      "2018-07-06 18:16:43.002055\n",
      "CorrectBackgroundAccurate  ready with: {'average_window': 10, 'bgshift_function': 'accurate'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Reconstruct  ready with: {'stack_clean': 0.02, 'forward_filter_option': 2, 'inverse_output_option': 0}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Focus  ready with: {'stacksummary_function': 'max_map', 'threshold': 0.9, 'increase_depth_of_field': True, 'focus_function': 'find_focus_sobel', 'merge_adjacent_particles': 2}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "segment\n",
      "clean\n",
      "  85 particles found\n",
      "Segment  ready with: {'threshold': 0.9}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "segment\n",
      "clean\n",
      "CalculateStats  ready with: {'export_outputpath': 'proc1', 'propnames': ['major_axis_length', 'minor_axis_length', 'equivalent_diameter', 'feret_diameter_max', 'equivalent_diameter_area']}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "statextract\n",
      "1.7% saturation\n",
      "measure\n",
      "  88 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 88 IMAGES from 88\n",
      "MergeStats  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "StatsToDisc  ready with: {'output_datafile': 'proc1/holotest'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Load  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "holo_test_data_01/001-2056.pgm\n",
      "D20180706T181648.002056\n",
      "2018-07-06 18:16:48.002056\n",
      "CorrectBackgroundAccurate  ready with: {'average_window': 10, 'bgshift_function': 'accurate'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Reconstruct  ready with: {'stack_clean': 0.02, 'forward_filter_option': 2, 'inverse_output_option': 0}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Focus  ready with: {'stacksummary_function': 'max_map', 'threshold': 0.9, 'increase_depth_of_field': True, 'focus_function': 'find_focus_sobel', 'merge_adjacent_particles': 2}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "segment\n",
      "clean\n",
      "  41 particles found\n",
      "Segment  ready with: {'threshold': 0.9}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "segment\n",
      "clean\n",
      "CalculateStats  ready with: {'export_outputpath': 'proc1', 'propnames': ['major_axis_length', 'minor_axis_length', 'equivalent_diameter', 'feret_diameter_max', 'equivalent_diameter_area']}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "statextract\n",
      "0.6% saturation\n",
      "measure\n",
      "  41 particles found\n",
      "WARNING. exportparticles temporarily modified for 2-d images without color!\n",
      "EXTRACTING 41 IMAGES from 41\n",
      "MergeStats  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "StatsToDisc  ready with: {'output_datafile': 'proc1/holotest'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Load  ready with: {}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "holo_test_data_01/001-2057.pgm\n",
      "D20180706T181654.002057\n",
      "2018-07-06 18:16:54.002057\n",
      "CorrectBackgroundAccurate  ready with: {'average_window': 10, 'bgshift_function': 'accurate'}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Reconstruct  ready with: {'stack_clean': 0.02, 'forward_filter_option': 2, 'inverse_output_option': 0}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "Focus  ready with: {'stacksummary_function': 'max_map', 'threshold': 0.9, 'increase_depth_of_field': True, 'focus_function': 'find_focus_sobel', 'merge_adjacent_particles': 2}  and data dict_keys(['cl', 'settings', 'raw_files', 'kern', 'im_stack', 'filename', 'timestamp', 'imraw', 'bgstack', 'imbg', 'imc', 'imss', 'stack_rp', 'stack_ifocus', 'imbw', 'stats'])\n",
      "segment\n",
      "clean\n",
      "  44 particles found\n"
     ]
    }
   ],
   "source": [
    "# get sorted list of input files\n",
    "files = sorted(glob(infolder))\n",
    "    \n",
    "#loop through file list - or here just use the first 5 files (+ 10 for initializing the background)\n",
    "for filename in files[:10+5]:\n",
    "    processing_pipeline.run(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 07 - Review outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstats = pyopia.io.load_stats(datafile_nc + '-STATS.nc')\n",
    "xstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyopia.statistics.count_images_in_stats(xstats), 'images found in stats data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the volume distribution from the stats DataFrame.\n",
    "dias, vd = pyopia.statistics.vd_from_stats(xstats, pyopia.pipeline.steps_from_xstats(xstats)['general']['pixel_size'])\n",
    "\n",
    "# plot the volume distribution\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(dias, vd)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('ECD [um]')\n",
    "plt.ylabel('Volume Distribution [uL/sample vol.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of focus locations\n",
    "import numpy as np\n",
    "\n",
    "pipeline_steps = pyopia.pipeline.steps_from_xstats(xstats)['steps']\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "zval = np.arange(pipeline_steps['initial']['minZ'],\n",
    "                 pipeline_steps['initial']['maxZ'],\n",
    "                 pipeline_steps['initial']['stepZ'])\n",
    "plt.hist(zval[xstats.ifocus-1],len(zval))\n",
    "plt.xlim(zval[0],zval[-1])\n",
    "plt.xlabel('Z [mm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create montage of focussed particles\n",
    "im_mont = pyopia.statistics.make_montage(datafile_nc + '-STATS.nc',\n",
    "                                         pyopia.pipeline.steps_from_xstats(xstats)['general'][\"pixel_size\"],\n",
    "                                         outfolder,\n",
    "                                         auto_scaler=1000, msize=2048, maxlength=100000, crop_stats=None, eyecandy=False)\n",
    "pyopia.plotting.montage_plot(im_mont, pyopia.pipeline.steps_from_xstats(xstats)['general'][\"pixel_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export rois of subset of particles (e.g. long, thin particles)\n",
    "min_major_axis_um = 100\n",
    "max_minor_axis_um = 40\n",
    "roifolder = 'long_thin_example'\n",
    "\n",
    "os.makedirs(roifolder, exist_ok=True)\n",
    "\n",
    "long_thin_parts=xstats.where((xstats['major_axis_length'] > min_major_axis_um/pyopia.pipeline.steps_from_xstats(xstats)['general'][\"pixel_size\"])\n",
    "                             & (xstats['minor_axis_length'] < max_minor_axis_um/pyopia.pipeline.steps_from_xstats(xstats)['general'][\"pixel_size\"]),\n",
    "                             drop=True)\n",
    "\n",
    "roifiles = pyopia.statistics.gen_roifiles(long_thin_parts)\n",
    "\n",
    "for roi in roifiles:\n",
    "    im = pyopia.statistics.export_name2im(roi, outfolder)\n",
    "    outfilename = os.path.join(roifolder ,roi + '.bmp')\n",
    "    skimage.io.imsave(outfilename,im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce1ed1d0a0c70742da6311dac6d4156324f6bcf6d9d02a2d90ecedc750502898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
