{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOLO version of TOML config file workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopia.background\n",
    "import pyopia.classify\n",
    "import pyopia.instrument.silcam\n",
    "import pyopia.instrument.holo\n",
    "import pyopia.io\n",
    "import pyopia.pipeline\n",
    "import pyopia.plotting\n",
    "import pyopia.process\n",
    "import pyopia.statistics\n",
    "import exampledata\n",
    "\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a TOML config file containing all setttings, and pipeline steps\n",
    "\n",
    "This creates a dict of all settings, which can be modified or writte in the same way as any other dictionary in python. This has a slightly different structure that the old 'steps' dict, but follows the same principle (look in the example config.toml file used below for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_settings = pyopia.io.load_toml('config-holo.toml')\n",
    "toml_settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "\n",
    "(same as before, but now giving Pipeline() the toml_setting dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the pipeline and run the initial steps\n",
    "processing_pipeline = pyopia.pipeline.Pipeline(toml_settings)\n",
    "\n",
    "# Load an image (from the test suite)\n",
    "filename = 'holo_test_data_01/001-2043.pgm'\n",
    "\n",
    "# Process the image to obtain the stats dataframe\n",
    "stats = processing_pipeline.run(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data again\n",
    "\n",
    "Then later, we can load the data again from NetCDF using xarray\n",
    "\n",
    "xarray DataSets are presented nicely in notebooks (rendered poorly on GitHub's webinterface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xarray.open_dataset('proc/test-STATS.nc') as xstats:\n",
    "    xstats.load()\n",
    "\n",
    "xstats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alter settings and re-process\n",
    "\n",
    "What if we wanted to re-process this dataset with a different segmentation threshold?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the TOML steps from the xarray DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_steps = pyopia.pipeline.steps_from_xstats(xstats)\n",
    "toml_steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter the setting we want to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_steps['steps']['focus']['stacksummary_function'] = 'std_map'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-process the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the pipeline and run the initial steps\n",
    "processing_pipeline = pyopia.pipeline.Pipeline(toml_steps)\n",
    "\n",
    "# Process the image to obtain the stats dataframe\n",
    "stats = processing_pipeline.run(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis\n",
    "\n",
    "At this point we could write this to disc again (using the pyopia.io.write_stats function)\n",
    "\n",
    "and/or we could build a new, correctly formatted, xarray for immediate use (which we will do here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstats_modified = pyopia.io.make_xstats(stats, toml_steps)\n",
    "xstats_modified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "We can plot directly from xarray in exactly the same way as from the Pandas DataFrame (so it doesn't matter which you use here). The benefit of 'xstats' as an xarray is that it now contains it's own metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dias, vd = pyopia.statistics.vd_from_stats(xstats, pyopia.pipeline.steps_from_xstats(xstats)['general']['pixel_size'])\n",
    "\n",
    "plt.plot(dias, vd, label=f\"Threshold={pyopia.pipeline.steps_from_xstats(xstats)['steps']['focus']['threshold']}\")\n",
    "plt.xscale('log')\n",
    "plt.xlabel('ECD [um]')\n",
    "plt.ylabel('Volume Distribution [uL/sample vol.]')\n",
    "\n",
    "dias_modified, vd_modified = pyopia.statistics.vd_from_stats(xstats_modified, pyopia.pipeline.steps_from_xstats(xstats_modified)['general']['pixel_size'])\n",
    "\n",
    "plt.plot(dias_modified, vd_modified, '--', label=f\"Threshold={pyopia.pipeline.steps_from_xstats(xstats_modified)['steps']['focus']['threshold']}\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining things to do/fix that are not covered in this notebook:\n",
    "\n",
    "* create a pyopia.main that does administration (instead of this notebook) and has command-line inputs with config.toml file as input\n",
    "* a pyopia.main should automatically setup the pipeline and process the images in settings['general']['raw_files'] file list in pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
