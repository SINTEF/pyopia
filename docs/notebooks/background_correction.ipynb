{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different ways to do background correction\n",
    "Background correction is an optional step in the analysis pipeline, and is used to remove static elements in an image for improved analysis results.\n",
    "\n",
    "In PyOpia there are several ways to use the background correction functionality, illustrated in this notebook.\n",
    "\n",
    "The default behavior is to set up the background for the first N images of a pipeline run, and not perform any analysis. \n",
    "After the background is completely set up, analysis starts (from image N), with either a dynamic running average or static background, depending on the configuration choices. You can customize the behavior you want by changing the configuration and by adding custom code, illustrated at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import rescale_intensity\n",
    "import zipfile\n",
    "\n",
    "import pyopia.exampledata\n",
    "from pyopia.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download example image files\n",
    "pyopia.exampledata.get_file_from_pysilcam_blob('oil.zip')\n",
    "with zipfile.ZipFile('oil.zip', 'r') as zipit:\n",
    "    zipit.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These imports are indirectly needed for the Pipeline\n",
    "import pyopia.background\n",
    "import pyopia.instrument.silcam\n",
    "\n",
    "# Manually define PyOpia pipeline configuration\n",
    "NUM_IMAGES_FOR_BACKGROUND = 5\n",
    "\n",
    "pipeline_config = {\n",
    "   'general': {\n",
    "      'raw_files': f'oil/*.silc',\n",
    "      'pixel_size': 24 # pixel size in um \n",
    "   },\n",
    " 'steps': {\n",
    "      ### start of steps applied to every image\n",
    "      # load the image using instrument-specific loading function \n",
    "      'load': {\n",
    "         'pipeline_class': 'pyopia.instrument.silcam.SilCamLoad'\n",
    "      },\n",
    "      # apply background correction - argument is which method to use:\n",
    "      # 'accurate' - recommended method for moving background\n",
    "      # 'fast' - faster method for realtime applications\n",
    "      # 'pass' - omit background correction\n",
    "      'correctbackground': {\n",
    "         'pipeline_class': 'pyopia.background.CorrectBackgroundAccurate',\n",
    "         'average_window': NUM_IMAGES_FOR_BACKGROUND,\n",
    "         'bgshift_function': 'pass',\n",
    "          'divide_bg': False\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "# now initialise the pipeline\n",
    "processing_pipeline = Pipeline(pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a background from multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The background stack (of raw images) and background image (mean of bgstack) is built during the first\n",
    "# N run steps of the pipeline. During this process, further analysis steps are skipped.\n",
    "\n",
    "# Get a sorted list of image files\n",
    "image_files = sorted(glob(pipeline_config['general']['raw_files']))\n",
    "print(f'Found {len(image_files)} image files')\n",
    "\n",
    "# Process first N images to create the background.\n",
    "for filename in image_files[:NUM_IMAGES_FOR_BACKGROUND]:\n",
    "    processing_pipeline.run(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the background image \n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(processing_pipeline.data['imbg'])\n",
    "#io.imsave('./background.bmp', (processing_pipeline.data['imbg']*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run background correction on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process one image using the already prepared background of the first N images\n",
    "# NB: Each time you call run(), the background stack and background image will be updated! (Unless 'pass' was set as bgshift_function - see below)\n",
    "processing_pipeline.run(image_files[NUM_IMAGES_FOR_BACKGROUND])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw and corrected image\n",
    "fig, axes = plt.subplots(1, 2, figsize=(2*6, 4))\n",
    "axes[0].imshow(processing_pipeline.data['imraw'])\n",
    "axes[0].set_title(f'Raw image #{NUM_IMAGES_FOR_BACKGROUND}')\n",
    "axes[1].imshow(processing_pipeline.data['im_corrected'])\n",
    "axes[1].set_title('Background corrected image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static vs running average background\n",
    "The CorrectBackgroundAccurate class have two different modes for a dynamic (running) background correction (bgshift_function either 'fast' and 'accurate'), \n",
    "and one mode for a static background that is created once and then not updated (bgshift_function='pass').\n",
    "The static background is set up in the same way as the dynamic one, by the N initial calls to the pipeline run. \n",
    "You can choose how many and which images to use for the background, illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate pipeline and update background step config for static background correction\n",
    "processing_pipeline = Pipeline(processing_pipeline.settings)\n",
    "processing_pipeline.settings['steps'].update(\n",
    "    {\n",
    "        'correctbackground':\n",
    "             {\n",
    "                'pipeline_class': 'pyopia.background.CorrectBackgroundAccurate',\n",
    "                'average_window': NUM_IMAGES_FOR_BACKGROUND,\n",
    "                'bgshift_function': 'pass'\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Process first N images to create the static background.\n",
    "for filename in image_files[:NUM_IMAGES_FOR_BACKGROUND]:\n",
    "    processing_pipeline.run(filename)\n",
    "\n",
    "# With a static background, the processing order does not matter, so we can for instance process the last image in the list.\n",
    "# Now processing an image will not cause the background to be updated\n",
    "imbg_before = processing_pipeline.data['imbg'].copy()\n",
    "processing_pipeline.run(image_files[-1])\n",
    "\n",
    "# Check difference in imbg before and after analysis step, should be zero\n",
    "np.abs(imbg_before - processing_pipeline.data['imbg']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct images by subtracting vs dividing average background\n",
    "The CorrectBackgroundAccurate class have two modes for a subtracting background correction (divide_bg=False), \n",
    "or dividing background correction (divide_bg=True) that provides the corrected image ('im_corrected') for further analysis.\n",
    "For dividing background mode, the zero-value pixels of the average background image are initially rescaled to 1/255 to prevent division by zero.\n",
    "For more information, refer to: https://doi.org/10.1016/j.marpolbul.2016.11.063).\n",
    "You can select the subtracting/dividing correction modes used in the pipeline to process raw images, as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected image uisng subtracting method\n",
    "im_corrected_subtract = processing_pipeline.data['im_corrected'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update pipeline config and background step with dividing background correction (divide_bg=True)\n",
    "\n",
    "pipeline_config['steps']['correctbackground']['divide_bg'] = True\n",
    "\n",
    "# Run the first N images to creat the background\n",
    "for filename in image_files[:NUM_IMAGES_FOR_BACKGROUND]:\n",
    "    processing_pipeline.run(filename)\n",
    "\n",
    "# Now process one of the raw images\n",
    "processing_pipeline.run(image_files[NUM_IMAGES_FOR_BACKGROUND])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected image uisng dividing mode\n",
    "im_corrected_division = processing_pipeline.data['im_corrected'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw, subtracing im_corrected and dividing im_corrected images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3*6, 5))\n",
    "axes[0].imshow(processing_pipeline.data['imraw'])\n",
    "axes[0].set_title(f'Raw image #{NUM_IMAGES_FOR_BACKGROUND}')\n",
    "axes[1].imshow(im_corrected_subtract)\n",
    "axes[1].set_title('Corrected image by background subtraction')\n",
    "axes[2].imshow(im_corrected_division)\n",
    "axes[2].set_title('Corrected image by background division')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom background correction\n",
    "You can write your own custom background correction class, here is a simple example of how to do that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomBackgroundClass():\n",
    "    '''\n",
    "    Example custom background class: use a randomly generated image to \"correct\" the background\n",
    "    '''\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # Create a random background image\n",
    "        data['imbg'] = np.random.random(data['imraw'].shape)\n",
    "        data['bgstack'] = [data['imbg']]\n",
    "\n",
    "        # Correct\n",
    "        data['im_corrected'] = np.maximum(data['imraw'] - data['imbg'], 0)\n",
    "\n",
    "        # Stretch contrast\n",
    "        data['im_corrected'] = rescale_intensity(data['im_corrected'], out_range=(0, 1))\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# Monkey patch the custom class into PyOpia\n",
    "pyopia.background.MyCustomBackgroundClass = MyCustomBackgroundClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate pipeline and update background step config with cutsom background correction\n",
    "processing_pipeline = Pipeline(processing_pipeline.settings)\n",
    "processing_pipeline.settings['steps'].update(\n",
    "    {\n",
    "        'correctbackground':\n",
    "             {\n",
    "                'pipeline_class': 'pyopia.background.MyCustomBackgroundClass',\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "processing_pipeline.run(image_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw and corrected image\n",
    "fig, axes = plt.subplots(1, 2, figsize=(2*6, 4))\n",
    "axes[0].imshow(processing_pipeline.data['imraw'])\n",
    "axes[0].set_title('Raw image')\n",
    "axes[1].imshow(processing_pipeline.data['im_corrected'])\n",
    "axes[1].set_title('Background corrected image')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopia",
   "language": "python",
   "name": "pyopia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
