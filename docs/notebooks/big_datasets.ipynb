{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dc6c46",
   "metadata": {},
   "source": [
    "(big-data)=\n",
    "# Big datasets\n",
    "\n",
    "If you have data containing a lot of particles, then there are some config settings that will significantly speed up processing. Here are some pointers.\n",
    "\n",
    "When processing, use the non-appending functionality in {class}`pyopia.io.StatsToDisc`\n",
    "\n",
    "```\n",
    "    [steps.output]\n",
    "    pipeline_class = 'pyopia.io.StatsToDisc'\n",
    "    output_datafile = 'proc/test' # prefix path for output nc file\n",
    "    append = false\n",
    "```\n",
    "\n",
    "Using the above output step in you pipeline will create a directory 'proc' filled with nc files conforming to the pattern: 'test-Image-D*-STATS.nc'\n",
    "\n",
    "These can be combined using {func}`pyopia.io.merge_and_save_mfdataset` of command line tool `pyopia merge-mfdata`, which will produce a new single -STATS.nc file of the whole dataset (for faster loading). Or you can do this manually like this:\n",
    "\n",
    "```python\n",
    "xstats, image_stats = pyopia.io.combine_stats_netcdf_files('proc/')\n",
    "```\n",
    "\n",
    "And the make a new nc file of the whole dataset for faster loading later:\n",
    "\n",
    "```python\n",
    "settings = pyopia.pipeline.steps_from_xstats(xstats)\n",
    "\n",
    "pyopia.io.write_stats(xstats.to_dataframe(),\n",
    "                      'proc/test2-test',\n",
    "                      settings,\n",
    "                      image_stats=image_stats.to_dataframe())\n",
    "\n",
    "xstats = pyopia.io.load_stats('proc/test2-test-STATS.nc')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bae4d6",
   "metadata": {},
   "source": [
    "# Parallell processing\n",
    "\n",
    "If you have data containing a lot of particles and/or a lot of raw images, you can use the num-chunks functionality in the {ref}(pyopia-process) command line tool e.g.:\n",
    "\n",
    "```bash\n",
    "pyopia process config.toml --num-chunks 4\n",
    "```\n",
    "\n",
    "This will split the list of raw files into 4 chunks to be processed in parallell using multiprocessing. This tool will organise the chunks of file names so that the appropriate background files into the correct places (i.e. for moving background, the last `average_window` number of files in the previous chunk are added to the start of the next chunk; and for fixed background the same initial `average_window` number of files are added to the top of each chunk)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('pyopia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "35ab0c005d63a5587fede8db5b2b16b081d9aece903d58f7211748c218ea86a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
